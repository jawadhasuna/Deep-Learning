{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Create Synthetic Video Dataset (circle vs square)\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "data_dir = '/content/synthetic_dataset'\n",
        "os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "num_classes = 2\n",
        "num_videos_per_class = 30   # zyada videos rakho for better accuracy\n",
        "video_length = 30           # Number of frames\n",
        "frame_height = 64\n",
        "frame_width = 64\n",
        "\n",
        "for class_id in range(num_classes):\n",
        "    class_dir = os.path.join(data_dir, f'class_{class_id}')\n",
        "    os.makedirs(class_dir, exist_ok=True)\n",
        "\n",
        "    for video_id in range(num_videos_per_class):\n",
        "        video_path = os.path.join(class_dir, f'video_{video_id}.avi')\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "        out = cv2.VideoWriter(video_path, fourcc, 20.0, (frame_width, frame_height))\n",
        "\n",
        "        for _ in range(video_length):\n",
        "            # Black background\n",
        "            frame = np.zeros((frame_height, frame_width, 3), dtype=np.uint8)\n",
        "\n",
        "            if class_id == 0:\n",
        "                # Class 0 = circle\n",
        "                cv2.circle(frame, (32, 32), 20, (0, 255, 0), -1)  # green circle\n",
        "            else:\n",
        "                # Class 1 = square\n",
        "                cv2.rectangle(frame, (20, 20), (44, 44), (255, 0, 0), -1)  # blue square\n",
        "\n",
        "            out.write(frame)\n",
        "\n",
        "        out.release()\n",
        "\n",
        "print(\"Synthetic video dataset (circle vs square) created!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jmlOR-_16r9",
        "outputId": "6578b8c0-48de-4a75-ccae-c9ffe6aac0ad"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synthetic video dataset (circle vs square) created!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wv1I6qJ1Jej3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Load the Synthetic Video Dataset\n",
        "def load_videos(data_dir, img_size=(128, 128), max_frames=30):\n",
        "    X, y = [], []\n",
        "    class_names = os.listdir(data_dir)\n",
        "\n",
        "    for label, class_name in enumerate(class_names):\n",
        "        class_dir = os.path.join(data_dir, class_name)\n",
        "        for video_file in os.listdir(class_dir):\n",
        "            video_path = os.path.join(class_dir, video_file)\n",
        "            cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "            frames = []\n",
        "            while len(frames) < max_frames:\n",
        "                ret, frame = cap.read()\n",
        "                if not ret:\n",
        "                    break\n",
        "                frame = cv2.resize(frame, img_size)\n",
        "                frames.append(frame)\n",
        "\n",
        "            if len(frames) == max_frames:\n",
        "                X.append(frames)\n",
        "                y.append(label)\n",
        "\n",
        "            cap.release()\n",
        "\n",
        "    return np.array(X), np.array(y), class_names\n",
        "\n",
        "X, y, class_names = load_videos(data_dir)\n",
        "X = X / 255.0  # Normalize the data"
      ],
      "metadata": {
        "id": "5ZDeDH1mI-zO"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Split the Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "\n",
        "# Step 4: Build the Model\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.optimizers import Adam # Import Adam optimizer\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Conv3D(16, (3, 3, 3), activation='relu', input_shape=(30, 128, 128, 3)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling3D((2, 2, 2)),\n",
        "    layers.Dropout(0.5),\n",
        "\n",
        "    layers.Conv3D(16, (3, 3, 3), activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling3D((2, 2, 2)),\n",
        "    layers.Dropout(0.5),\n",
        "\n",
        "    layers.Conv3D(16, (3, 3, 3), activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling3D((2, 2, 2)),\n",
        "    layers.Dropout(0.5),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(len(class_names), activation='softmax')\n",
        "])\n",
        "\n",
        "# Instantiate the Adam optimizer with the desired learning rate\n",
        "adam_optimizer = Adam(learning_rate=0.0001)\n",
        "\n",
        "model.compile(optimizer=adam_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 5: Train the Model\n",
        "model.fit(X_train, y_train, epochs=7, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Step 6: Evaluate the Model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f'Test accuracy: {test_acc:.2f}')\n",
        "\n",
        "# Step 7: Save the Model\n",
        "model.save('video_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veQAlLdDJh-5",
        "outputId": "c8d16d66-7c24-40ab-a93a-b97b54d32516"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4s/step - accuracy: 0.4903 - loss: 2.6647 - val_accuracy: 0.4643 - val_loss: 0.6769\n",
            "Epoch 2/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 397ms/step - accuracy: 0.6674 - loss: 1.5144 - val_accuracy: 0.4643 - val_loss: 0.6696\n",
            "Epoch 3/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 397ms/step - accuracy: 0.7816 - loss: 0.4989 - val_accuracy: 0.4643 - val_loss: 0.6674\n",
            "Epoch 4/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 541ms/step - accuracy: 0.8309 - loss: 0.5252 - val_accuracy: 0.4643 - val_loss: 0.6603\n",
            "Epoch 5/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 541ms/step - accuracy: 0.8544 - loss: 0.3871 - val_accuracy: 0.4643 - val_loss: 0.6483\n",
            "Epoch 6/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 395ms/step - accuracy: 0.9488 - loss: 0.1467 - val_accuracy: 1.0000 - val_loss: 0.6414\n",
            "Epoch 7/7\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 541ms/step - accuracy: 0.9548 - loss: 0.1120 - val_accuracy: 1.0000 - val_loss: 0.6390\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 0.6389\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 1.00\n"
          ]
        }
      ]
    }
  ]
}